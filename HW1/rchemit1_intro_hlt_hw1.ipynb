{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLm_JxCxrkIE",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "In the first assignment, you will implement some of the algorithms you have learnt in the first two weeks of lectures: n-gram language models, and syntactic parsing using the CYK algorithm.\n",
        "\n",
        "# Setup\n",
        "\n",
        "For this and other assignments, we will be using Google Colab, for both code as well as descriptive questions. Your task is to finish all the questions in the Colab notebook and then upload a PDF version of the notebook, and a viewable link on Gradescope.\n",
        "\n",
        "### Google colaboratory\n",
        "\n",
        "Before getting started, get familiar with google colaboratory:\n",
        "https://colab.research.google.com/notebooks/welcome.ipynb\n",
        "\n",
        "This is a neat python environment that works in the cloud and does not require you to\n",
        "set up anything on your personal machine\n",
        "(it also has some built-in IDE features that make writing code easier).\n",
        "Moreover, it allows you to copy any existing collaboratory file, alter it and share\n",
        "with other people.\n",
        "\n",
        "### Submission\n",
        "\n",
        "Before you start working on this homework do the following steps:\n",
        "\n",
        "1. Press __File > Save a copy in Drive...__ tab. This will allow you to have your own copy and change it.\n",
        "2. Follow all the steps in this collaboratory file and write / change / uncomment code as necessary.\n",
        "3. Do not forget to occasionally press __File > Save__ tab to save your progress.\n",
        "4. After all the changes are done and progress is saved press __Share__ button (top right corner of the page), press __get shareable link__ and make sure you have the option __Anyone with the link can view__ selected. Copy the link and paste it in the box below.\n",
        "5. After completing the notebook, press __File > Download .ipynb__ to download a local copy on your computer, and then upload the file to Gradescope.\n",
        "\n",
        "\n",
        "__Paste your notebook link in the box below.__ _(0 points)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inEvaul0l3GR"
      },
      "source": [
        "https://colab.research.google.com/drive/1cnDgl7hqNgmGANwnHajak3-7zauo63gm?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "scrolled": true,
        "id": "51H53CHOl3GR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ef93124-e1b1-43db-dbae-85179f3f68c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-17 00:58:51--  https://github.com/jhu-intro-hlt/jhu-intro-hlt.github.io/raw/master/assignments/hw1-files/student/required_files.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/jhu-intro-hlt/jhu-intro-hlt.github.io/master/assignments/hw1-files/student/required_files.zip [following]\n",
            "--2025-09-17 00:58:51--  https://raw.githubusercontent.com/jhu-intro-hlt/jhu-intro-hlt.github.io/master/assignments/hw1-files/student/required_files.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11474 (11K) [application/zip]\n",
            "Saving to: ‘required_files.zip’\n",
            "\n",
            "required_files.zip  100%[===================>]  11.21K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-09-17 00:58:51 (31.1 MB/s) - ‘required_files.zip’ saved [11474/11474]\n",
            "\n",
            "Archive:  required_files.zip\n",
            "  inflating: requirements.txt        \n",
            "   creating: tests/\n",
            "  inflating: tests/cfg-iscnf.py      \n",
            "  inflating: tests/cfg-tocnf.py      \n",
            "  inflating: tests/cyk-impl.py       \n",
            "  inflating: tests/ngramlm-corpus-size.py  \n",
            "  inflating: tests/ngramlm-empirical-distribution.py  \n",
            "  inflating: tests/ngramlm-impl.py   \n",
            "  inflating: tests/ngramlm-improvement-impl.py  \n",
            "  inflating: tests/ngramlm-laplace-smoothing-impl.py  \n",
            "  inflating: tests/ngramlm-laplace-smoothing-perp.py  \n",
            "  inflating: tests/ngramlm-perp-impl.py  \n",
            "  inflating: tests/ngramlm-quad-perp-on-training.py  \n",
            "  inflating: tests/ngramlm-tri-perp-on-dev.py  \n",
            "  inflating: tests/ngramlm-tri-perp-on-training.py  \n",
            "  inflating: tests/ngramlm-vocab-size.py  \n",
            "  inflating: tests/warmup-ngram.py   \n",
            "Collecting datascience (from -r requirements.txt (line 1))\n",
            "  Downloading datascience-0.18.0-py3-none-any.whl.metadata (910 bytes)\n",
            "Requirement already satisfied: jupyter_client in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (7.4.9)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (6.17.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (7.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (1.16.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (3.1.6)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (7.16.6)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (5.10.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (0.3.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (2.0.2)\n",
            "Collecting otter-grader==4.0.1 (from -r requirements.txt (line 15))\n",
            "  Downloading otter_grader-4.0.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting pdfkit (from -r requirements.txt (line 17))\n",
            "  Downloading pdfkit-1.0.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting PyPDF2 (from -r requirements.txt (line 18))\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (3.9.1)\n",
            "Collecting jupyter (from -r requirements.txt (line 23))\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting overrides===6.2.0 (from -r requirements.txt (line 24))\n",
            "  Downloading overrides-6.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from otter-grader==4.0.1->-r requirements.txt (line 15)) (6.0.2)\n",
            "Collecting python-on-whales (from otter-grader==4.0.1->-r requirements.txt (line 15))\n",
            "  Downloading python_on_whales-0.78.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from otter-grader==4.0.1->-r requirements.txt (line 15)) (2.32.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from otter-grader==4.0.1->-r requirements.txt (line 15)) (1.17.3)\n",
            "Requirement already satisfied: jupytext in /usr/local/lib/python3.12/dist-packages (from otter-grader==4.0.1->-r requirements.txt (line 15)) (1.17.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from otter-grader==4.0.1->-r requirements.txt (line 15)) (8.2.1)\n",
            "Collecting fica>=0.2.0 (from otter-grader==4.0.1->-r requirements.txt (line 15))\n",
            "  Downloading fica-0.4.1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from otter-grader==4.0.1->-r requirements.txt (line 15)) (2.181.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.12/dist-packages (from otter-grader==4.0.1->-r requirements.txt (line 15)) (1.2.2)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.12/dist-packages (from otter-grader==4.0.1->-r requirements.txt (line 15)) (6.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from otter-grader==4.0.1->-r requirements.txt (line 15)) (1.17.0)\n",
            "Requirement already satisfied: folium>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from datascience->-r requirements.txt (line 1)) (0.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from datascience->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from datascience->-r requirements.txt (line 1)) (7.34.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from datascience->-r requirements.txt (line 1)) (5.24.1)\n",
            "Requirement already satisfied: branca in /usr/local/lib/python3.12/dist-packages (from datascience->-r requirements.txt (line 1)) (0.8.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter_client->-r requirements.txt (line 2)) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter_client->-r requirements.txt (line 2)) (5.8.1)\n",
            "Requirement already satisfied: nest-asyncio>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from jupyter_client->-r requirements.txt (line 2)) (1.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter_client->-r requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.12/dist-packages (from jupyter_client->-r requirements.txt (line 2)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from jupyter_client->-r requirements.txt (line 2)) (6.4.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.12/dist-packages (from jupyter_client->-r requirements.txt (line 2)) (5.7.1)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 3)) (1.8.15)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 3)) (0.1.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 5)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 5)) (2025.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->-r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->-r requirements.txt (line 6)) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->-r requirements.txt (line 6)) (3.0.15)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->-r requirements.txt (line 10)) (3.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert->-r requirements.txt (line 11)) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->-r requirements.txt (line 11)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert->-r requirements.txt (line 11)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert->-r requirements.txt (line 11)) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert->-r requirements.txt (line 11)) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->-r requirements.txt (line 11)) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->-r requirements.txt (line 11)) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->-r requirements.txt (line 11)) (2.19.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->-r requirements.txt (line 12)) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->-r requirements.txt (line 12)) (4.25.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 20)) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 20)) (4.67.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.12/dist-packages (from jupyter->-r requirements.txt (line 23)) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.12/dist-packages (from jupyter->-r requirements.txt (line 23)) (6.6.3)\n",
            "Collecting jupyterlab (from jupyter->-r requirements.txt (line 23))\n",
            "  Downloading jupyterlab-4.4.7-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->-r requirements.txt (line 11)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->-r requirements.txt (line 11)) (1.4.0)\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.12/dist-packages (from fica>=0.2.0->otter-grader==4.0.1->-r requirements.txt (line 15)) (0.21.2)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.12/dist-packages (from fica>=0.2.0->otter-grader==4.0.1->-r requirements.txt (line 15)) (8.2.3)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.12/dist-packages (from folium>=0.9.1->datascience->-r requirements.txt (line 1)) (2025.4.0)\n",
            "Collecting jedi>=0.16 (from ipython->datascience->-r requirements.txt (line 1))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython->datascience->-r requirements.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->datascience->-r requirements.txt (line 1)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->datascience->-r requirements.txt (line 1)) (3.0.52)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->datascience->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->datascience->-r requirements.txt (line 1)) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->-r requirements.txt (line 12)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->-r requirements.txt (line 12)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->-r requirements.txt (line 12)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->-r requirements.txt (line 12)) (0.27.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter_client->-r requirements.txt (line 2)) (4.4.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r requirements.txt (line 23)) (25.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r requirements.txt (line 23)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r requirements.txt (line 23)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r requirements.txt (line 23)) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r requirements.txt (line 23)) (1.3.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert->-r requirements.txt (line 11)) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert->-r requirements.txt (line 11)) (4.15.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->otter-grader==4.0.1->-r requirements.txt (line 15)) (0.30.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->otter-grader==4.0.1->-r requirements.txt (line 15)) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->otter-grader==4.0.1->-r requirements.txt (line 15)) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->otter-grader==4.0.1->-r requirements.txt (line 15)) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->otter-grader==4.0.1->-r requirements.txt (line 15)) (4.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib->otter-grader==4.0.1->-r requirements.txt (line 15)) (2.0.0)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter->-r requirements.txt (line 23))\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r requirements.txt (line 23)) (0.28.1)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter->-r requirements.txt (line 23))\n",
            "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r requirements.txt (line 23)) (2.14.0)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter->-r requirements.txt (line 23))\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r requirements.txt (line 23)) (0.2.4)\n",
            "Requirement already satisfied: markdown-it-py>=1.0 in /usr/local/lib/python3.12/dist-packages (from jupytext->otter-grader==4.0.1->-r requirements.txt (line 15)) (4.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.12/dist-packages (from jupytext->otter-grader==4.0.1->-r requirements.txt (line 15)) (0.5.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->datascience->-r requirements.txt (line 1)) (8.5.0)\n",
            "Requirement already satisfied: pydantic!=2.0.*,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from python-on-whales->otter-grader==4.0.1->-r requirements.txt (line 15)) (2.11.7)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->otter-grader==4.0.1->-r requirements.txt (line 15)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->otter-grader==4.0.1->-r requirements.txt (line 15)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->otter-grader==4.0.1->-r requirements.txt (line 15)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->otter-grader==4.0.1->-r requirements.txt (line 15)) (2025.8.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client->otter-grader==4.0.1->-r requirements.txt (line 15)) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client->otter-grader==4.0.1->-r requirements.txt (line 15)) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client->otter-grader==4.0.1->-r requirements.txt (line 15)) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client->otter-grader==4.0.1->-r requirements.txt (line 15)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client->otter-grader==4.0.1->-r requirements.txt (line 15)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client->otter-grader==4.0.1->-r requirements.txt (line 15)) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (0.16.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->datascience->-r requirements.txt (line 1)) (0.8.5)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (0.5.3)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 23)) (25.1.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 23)) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 23))\n",
            "  Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=1.0->jupytext->otter-grader==4.0.1->-r requirements.txt (line 15)) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->datascience->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->datascience->-r requirements.txt (line 1)) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales->otter-grader==4.0.1->-r requirements.txt (line 15)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales->otter-grader==4.0.1->-r requirements.txt (line 15)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales->otter-grader==4.0.1->-r requirements.txt (line 15)) (0.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->otter-grader==4.0.1->-r requirements.txt (line 15)) (3.3.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.2.0->otter-grader==4.0.1->-r requirements.txt (line 15)) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.2.0->otter-grader==4.0.1->-r requirements.txt (line 15)) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.2.0->otter-grader==4.0.1->-r requirements.txt (line 15)) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.2.0->otter-grader==4.0.1->-r requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.2.0->otter-grader==4.0.1->-r requirements.txt (line 15)) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.2.0->otter-grader==4.0.1->-r requirements.txt (line 15)) (2.0.0)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.2.0->otter-grader==4.0.1->-r requirements.txt (line 15)) (3.0.1)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.2.0->otter-grader==4.0.1->-r requirements.txt (line 15)) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.2.0->otter-grader==4.0.1->-r requirements.txt (line 15)) (1.4.1)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.2.0->otter-grader==4.0.1->-r requirements.txt (line 15)) (3.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (1.3.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (3.3.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (0.1.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client->otter-grader==4.0.1->-r requirements.txt (line 15)) (0.6.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 23)) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 23)) (2.23)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (24.11.1)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (1.2.2)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 23)) (2.9.0.20250822)\n",
            "Downloading otter_grader-4.0.1-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.9/166.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-6.2.0-py3-none-any.whl (17 kB)\n",
            "Downloading datascience-0.18.0-py3-none-any.whl (725 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.0/725.0 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfkit-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading fica-0.4.1-py3-none-any.whl (13 kB)\n",
            "Downloading jupyterlab-4.4.7-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_on_whales-0.78.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: pdfkit, PyPDF2, overrides, json5, jedi, async-lru, python-on-whales, fica, datascience, otter-grader, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter\n",
            "  Attempting uninstall: overrides\n",
            "    Found existing installation: overrides 7.7.0\n",
            "    Uninstalling overrides-7.7.0:\n",
            "      Successfully uninstalled overrides-7.7.0\n",
            "Successfully installed PyPDF2-3.0.1 async-lru-2.0.5 datascience-0.18.0 fica-0.4.1 jedi-0.19.2 json5-0.12.1 jupyter-1.1.1 jupyter-lsp-2.3.0 jupyterlab-4.4.7 jupyterlab-server-2.27.3 otter-grader-4.0.1 overrides-6.2.0 pdfkit-1.0.0 python-on-whales-0.78.0\n"
          ]
        }
      ],
      "source": [
        "# Downloads required packages and files\n",
        "required_files = \"https://github.com/jhu-intro-hlt/jhu-intro-hlt.github.io/raw/master/assignments/hw1-files/student/required_files.zip\"\n",
        "! wget $required_files && unzip -o required_files.zip\n",
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pEX1BnxNl3GS"
      },
      "outputs": [],
      "source": [
        "# Initialize Otter\n",
        "import otter\n",
        "grader = otter.Notebook(colab=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "616QyAz3l3GS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6162da4-48cf-4aee-cfc2-4a72dc41c46d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import random\n",
        "import math\n",
        "import re\n",
        "import os\n",
        "import urllib\n",
        "import json\n",
        "from typing import *\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import RegexpTokenizer, sent_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWXKLhH1N0IU",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Part 1: N-gram Language Models\n",
        "\n",
        "For the first part of this assignment, you will implement a trigram language model and train it on a small corpus. You will then implement a scoring function to compute the perplexity of the model on a held-out test set. Finally, you will implement some methods to deal with sparsity (zero count) issues in your model.\n",
        "\n",
        "To ease you into the implementation, we will provide some boilerplate code that you would need to fill in depending upon the functionalities the code is supposed to perform. For the first few sections below, we will use the complete text from Leo Tolstoy's \"War and Peace,\" which is freely available from [Project Gutenberg](https://www.gutenberg.org/). Run the following code block to download the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fmw2bHZPl3GT"
      },
      "outputs": [],
      "source": [
        "def download_data():\n",
        "    def _download(url: str, filename: str) -> str:\n",
        "        txt = urllib.request.urlopen(url)\n",
        "        with open(filename, 'w') as f:\n",
        "            f.write(txt.read().decode('utf-8'))\n",
        "\n",
        "    _download('https://cs.stanford.edu/people/karpathy/char-rnn/warpeace_input.txt', 'warpeace_input.txt')\n",
        "    _download('http://www.gutenberg.org/files/1399/1399-0.txt', '1399-0.txt')\n",
        "\n",
        "download_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obJJmlMlSs2d",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The complete text downloaded above contains punctuations which are not important for our purposes. So we will perform a basic text preprocessing using the [NLTK toolkit](https://www.nltk.org/). We will store the processed text into a list of strings, where each string will contain words without any punctuations. We will also convert all words to lower case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eoKZKaRGVYa1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Loading the text\n",
        "try:\n",
        "    with open('warpeace_input.txt', 'r') as file:\n",
        "        corpus_raw = file.read().replace('\\n', ' ')\n",
        "except FileNotFoundError:\n",
        "    with open('../../warpeace_input.txt', 'r') as file:\n",
        "        corpus_raw = file.read().replace('\\n', ' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1r_Q1XbTWCst",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61eabe6f-ec7a-446d-aa1f-20b088f908c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus has 32040 sentences\n"
          ]
        }
      ],
      "source": [
        "sentences = sent_tokenize(corpus_raw)\n",
        "\n",
        "corpus = []\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "for sentence in sentences:\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    corpus.append([token.lower() for token in tokens])\n",
        "\n",
        "print(\"Corpus has {} sentences\".format(len(corpus)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykO86GMkPQ2E",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Warm-up: n-gram counts from a corpus\n",
        "\n",
        "Let's start with implementing a simple function for obtaining n-grams and their counts from a string. Complete the following function. _(5 points)_\n",
        "\n",
        "__Note 1:__ Use the special token `~` for both beginning of sentence (BOS) and end of sentence (EOS) tokens. For example, the sentence \"Mary has a little lamb\" has the bigrams \"_~ Mary_\", \"_Mary has_\", \"_has a_\", \"_a little_\", \"_little lamb_\", and \"_lamb ~_\".\n",
        "\n",
        "__Note 2:__ You don't need to do any further text processing beyond what has already been done before.\n",
        "\n",
        "__Note 3:__ For the usage of `collections.Counter`, you can refer to [its python doc](https://docs.python.org/3/library/collections.html#collections.Counter)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "id": "2e33ebbwl3GU"
      },
      "outputs": [],
      "source": [
        "def generate_ngrams(text: List[str], n: int) -> Counter:\n",
        "    \"\"\"Generates all n-grams (i.e. n-1 context words) for the given text.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    text : List[str]\n",
        "        Input text (list of strings) after tokenization.\n",
        "    n : int\n",
        "        n-gram parameter (must be greater than or equal to 1).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ngrams : Counter\n",
        "        Output n-grams dictionary as {ngram: count} (Dict[Tuple, int]),\n",
        "        where `ngram` is a n-gram tuple and `count` is an integer count.\n",
        "        e.g. ('Mary','has') and value as count of the n-gram in the text.\n",
        "    \"\"\"\n",
        "    assert (isinstance(n, int) and n > 0)\n",
        "\n",
        "    ngrams = Counter()\n",
        "\n",
        "    # TODO: Your code here.\n",
        "    ...\n",
        "    ap_text = ['~'] * (n - 1) + text + ['~'] * (n - 1)\n",
        "    for i in range(len(ap_text) - n + 1):\n",
        "        ngrams[tuple(ap_text[i:i+n])] += 1\n",
        "\n",
        "    return ngrams\n",
        "\n",
        "\n",
        "def generate_ngrams_sentences(text: List[List[str]], n: int) -> Counter:\n",
        "    \"\"\"Generates n-grams for each sentence and aggregates them.\"\"\"\n",
        "    all_ngrams = Counter()\n",
        "    for sentence in text:\n",
        "        all_ngrams.update(generate_ngrams(sentence, n))\n",
        "    return all_ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": true,
        "tags": [],
        "id": "b9nXynL4l3GV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e45c65a-2cd5-4866-8da4-8b82269e04b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['well', 'prince', 'so', 'genoa', 'and', 'lucca', 'are', 'now', 'just', 'family', 'estates', 'of', 'the', 'buonapartes'], ['but', 'i', 'warn', 'you', 'if', 'you', 'don', 't', 'tell', 'me', 'that', 'this', 'means', 'war', 'if', 'you', 'still', 'try', 'to', 'defend', 'the', 'infamies', 'and', 'horrors', 'perpetrated', 'by', 'that', 'antichrist', 'i', 'really', 'believe', 'he', 'is', 'antichrist', 'i', 'will', 'have', 'nothing', 'more', 'to', 'do', 'with', 'you', 'and', 'you', 'are', 'no', 'longer', 'my', 'friend', 'no', 'longer', 'my', 'faithful', 'slave', 'as', 'you', 'call', 'yourself'], ['but', 'how', 'do', 'you', 'do'], ['i', 'see', 'i', 'have', 'frightened', 'you', 'sit', 'down', 'and', 'tell', 'me', 'all', 'the', 'news'], ['it', 'was', 'in', 'july', '1805', 'and', 'the', 'speaker', 'was', 'the', 'well', 'known', 'anna', 'pavlovna', 'scherer', 'maid', 'of', 'honor', 'and', 'favorite', 'of', 'the', 'empress', 'marya', 'fedorovna'], ['with', 'these', 'words', 'she', 'greeted', 'prince', 'vasili', 'kuragin', 'a', 'man', 'of', 'high', 'rank', 'and', 'importance', 'who', 'was', 'the', 'first', 'to', 'arrive', 'at', 'her', 'reception'], ['anna', 'pavlovna', 'had', 'had', 'a', 'cough', 'for', 'some', 'days'], ['she', 'was', 'as', 'she', 'said', 'suffering', 'from', 'la', 'grippe', 'grippe', 'being', 'then', 'a', 'new', 'word', 'in', 'st', 'petersburg', 'used', 'only', 'by', 'the', 'elite'], ['all', 'her', 'invitations', 'without', 'exception', 'written', 'in', 'french', 'and', 'delivered', 'by', 'a', 'scarlet', 'liveried', 'footman', 'that', 'morning', 'ran', 'as', 'follows', 'if', 'you', 'have', 'nothing', 'better', 'to', 'do', 'count', 'or', 'prince', 'and', 'if', 'the', 'prospect', 'of', 'spending', 'an', 'evening', 'with', 'a', 'poor', 'invalid', 'is', 'not', 'too', 'terrible', 'i', 'shall', 'be', 'very', 'charmed', 'to', 'see', 'you', 'tonight', 'between', '7', 'and', '10', 'annette', 'scherer'], ['heavens']]\n",
            "Counter({('~', '~', 'but'): 2, ('no', 'longer', 'my'): 2, ('~', '~', 'well'): 1, ('~', 'well', 'prince'): 1, ('well', 'prince', 'so'): 1, ('prince', 'so', 'genoa'): 1, ('so', 'genoa', 'and'): 1, ('genoa', 'and', 'lucca'): 1, ('and', 'lucca', 'are'): 1, ('lucca', 'are', 'now'): 1, ('are', 'now', 'just'): 1, ('now', 'just', 'family'): 1, ('just', 'family', 'estates'): 1, ('family', 'estates', 'of'): 1, ('estates', 'of', 'the'): 1, ('of', 'the', 'buonapartes'): 1, ('the', 'buonapartes', '~'): 1, ('buonapartes', '~', '~'): 1, ('~', 'but', 'i'): 1, ('but', 'i', 'warn'): 1, ('i', 'warn', 'you'): 1, ('warn', 'you', 'if'): 1, ('you', 'if', 'you'): 1, ('if', 'you', 'don'): 1, ('you', 'don', 't'): 1, ('don', 't', 'tell'): 1, ('t', 'tell', 'me'): 1, ('tell', 'me', 'that'): 1, ('me', 'that', 'this'): 1, ('that', 'this', 'means'): 1, ('this', 'means', 'war'): 1, ('means', 'war', 'if'): 1, ('war', 'if', 'you'): 1, ('if', 'you', 'still'): 1, ('you', 'still', 'try'): 1, ('still', 'try', 'to'): 1, ('try', 'to', 'defend'): 1, ('to', 'defend', 'the'): 1, ('defend', 'the', 'infamies'): 1, ('the', 'infamies', 'and'): 1, ('infamies', 'and', 'horrors'): 1, ('and', 'horrors', 'perpetrated'): 1, ('horrors', 'perpetrated', 'by'): 1, ('perpetrated', 'by', 'that'): 1, ('by', 'that', 'antichrist'): 1, ('that', 'antichrist', 'i'): 1, ('antichrist', 'i', 'really'): 1, ('i', 'really', 'believe'): 1, ('really', 'believe', 'he'): 1, ('believe', 'he', 'is'): 1, ('he', 'is', 'antichrist'): 1, ('is', 'antichrist', 'i'): 1, ('antichrist', 'i', 'will'): 1, ('i', 'will', 'have'): 1, ('will', 'have', 'nothing'): 1, ('have', 'nothing', 'more'): 1, ('nothing', 'more', 'to'): 1, ('more', 'to', 'do'): 1, ('to', 'do', 'with'): 1, ('do', 'with', 'you'): 1, ('with', 'you', 'and'): 1, ('you', 'and', 'you'): 1, ('and', 'you', 'are'): 1, ('you', 'are', 'no'): 1, ('are', 'no', 'longer'): 1, ('longer', 'my', 'friend'): 1, ('my', 'friend', 'no'): 1, ('friend', 'no', 'longer'): 1, ('longer', 'my', 'faithful'): 1, ('my', 'faithful', 'slave'): 1, ('faithful', 'slave', 'as'): 1, ('slave', 'as', 'you'): 1, ('as', 'you', 'call'): 1, ('you', 'call', 'yourself'): 1, ('call', 'yourself', '~'): 1, ('yourself', '~', '~'): 1, ('~', 'but', 'how'): 1, ('but', 'how', 'do'): 1, ('how', 'do', 'you'): 1, ('do', 'you', 'do'): 1, ('you', 'do', '~'): 1, ('do', '~', '~'): 1, ('~', '~', 'i'): 1, ('~', 'i', 'see'): 1, ('i', 'see', 'i'): 1, ('see', 'i', 'have'): 1, ('i', 'have', 'frightened'): 1, ('have', 'frightened', 'you'): 1, ('frightened', 'you', 'sit'): 1, ('you', 'sit', 'down'): 1, ('sit', 'down', 'and'): 1, ('down', 'and', 'tell'): 1, ('and', 'tell', 'me'): 1, ('tell', 'me', 'all'): 1, ('me', 'all', 'the'): 1, ('all', 'the', 'news'): 1, ('the', 'news', '~'): 1, ('news', '~', '~'): 1, ('~', '~', 'it'): 1, ('~', 'it', 'was'): 1, ('it', 'was', 'in'): 1, ('was', 'in', 'july'): 1, ('in', 'july', '1805'): 1, ('july', '1805', 'and'): 1, ('1805', 'and', 'the'): 1, ('and', 'the', 'speaker'): 1, ('the', 'speaker', 'was'): 1, ('speaker', 'was', 'the'): 1, ('was', 'the', 'well'): 1, ('the', 'well', 'known'): 1, ('well', 'known', 'anna'): 1, ('known', 'anna', 'pavlovna'): 1, ('anna', 'pavlovna', 'scherer'): 1, ('pavlovna', 'scherer', 'maid'): 1, ('scherer', 'maid', 'of'): 1, ('maid', 'of', 'honor'): 1, ('of', 'honor', 'and'): 1, ('honor', 'and', 'favorite'): 1, ('and', 'favorite', 'of'): 1, ('favorite', 'of', 'the'): 1, ('of', 'the', 'empress'): 1, ('the', 'empress', 'marya'): 1, ('empress', 'marya', 'fedorovna'): 1, ('marya', 'fedorovna', '~'): 1, ('fedorovna', '~', '~'): 1, ('~', '~', 'with'): 1, ('~', 'with', 'these'): 1, ('with', 'these', 'words'): 1, ('these', 'words', 'she'): 1, ('words', 'she', 'greeted'): 1, ('she', 'greeted', 'prince'): 1, ('greeted', 'prince', 'vasili'): 1, ('prince', 'vasili', 'kuragin'): 1, ('vasili', 'kuragin', 'a'): 1, ('kuragin', 'a', 'man'): 1, ('a', 'man', 'of'): 1, ('man', 'of', 'high'): 1, ('of', 'high', 'rank'): 1, ('high', 'rank', 'and'): 1, ('rank', 'and', 'importance'): 1, ('and', 'importance', 'who'): 1, ('importance', 'who', 'was'): 1, ('who', 'was', 'the'): 1, ('was', 'the', 'first'): 1, ('the', 'first', 'to'): 1, ('first', 'to', 'arrive'): 1, ('to', 'arrive', 'at'): 1, ('arrive', 'at', 'her'): 1, ('at', 'her', 'reception'): 1, ('her', 'reception', '~'): 1, ('reception', '~', '~'): 1, ('~', '~', 'anna'): 1, ('~', 'anna', 'pavlovna'): 1, ('anna', 'pavlovna', 'had'): 1, ('pavlovna', 'had', 'had'): 1, ('had', 'had', 'a'): 1, ('had', 'a', 'cough'): 1, ('a', 'cough', 'for'): 1, ('cough', 'for', 'some'): 1, ('for', 'some', 'days'): 1, ('some', 'days', '~'): 1, ('days', '~', '~'): 1, ('~', '~', 'she'): 1, ('~', 'she', 'was'): 1, ('she', 'was', 'as'): 1, ('was', 'as', 'she'): 1, ('as', 'she', 'said'): 1, ('she', 'said', 'suffering'): 1, ('said', 'suffering', 'from'): 1, ('suffering', 'from', 'la'): 1, ('from', 'la', 'grippe'): 1, ('la', 'grippe', 'grippe'): 1, ('grippe', 'grippe', 'being'): 1, ('grippe', 'being', 'then'): 1, ('being', 'then', 'a'): 1, ('then', 'a', 'new'): 1, ('a', 'new', 'word'): 1, ('new', 'word', 'in'): 1, ('word', 'in', 'st'): 1, ('in', 'st', 'petersburg'): 1, ('st', 'petersburg', 'used'): 1, ('petersburg', 'used', 'only'): 1, ('used', 'only', 'by'): 1, ('only', 'by', 'the'): 1, ('by', 'the', 'elite'): 1, ('the', 'elite', '~'): 1, ('elite', '~', '~'): 1, ('~', '~', 'all'): 1, ('~', 'all', 'her'): 1, ('all', 'her', 'invitations'): 1, ('her', 'invitations', 'without'): 1, ('invitations', 'without', 'exception'): 1, ('without', 'exception', 'written'): 1, ('exception', 'written', 'in'): 1, ('written', 'in', 'french'): 1, ('in', 'french', 'and'): 1, ('french', 'and', 'delivered'): 1, ('and', 'delivered', 'by'): 1, ('delivered', 'by', 'a'): 1, ('by', 'a', 'scarlet'): 1, ('a', 'scarlet', 'liveried'): 1, ('scarlet', 'liveried', 'footman'): 1, ('liveried', 'footman', 'that'): 1, ('footman', 'that', 'morning'): 1, ('that', 'morning', 'ran'): 1, ('morning', 'ran', 'as'): 1, ('ran', 'as', 'follows'): 1, ('as', 'follows', 'if'): 1, ('follows', 'if', 'you'): 1, ('if', 'you', 'have'): 1, ('you', 'have', 'nothing'): 1, ('have', 'nothing', 'better'): 1, ('nothing', 'better', 'to'): 1, ('better', 'to', 'do'): 1, ('to', 'do', 'count'): 1, ('do', 'count', 'or'): 1, ('count', 'or', 'prince'): 1, ('or', 'prince', 'and'): 1, ('prince', 'and', 'if'): 1, ('and', 'if', 'the'): 1, ('if', 'the', 'prospect'): 1, ('the', 'prospect', 'of'): 1, ('prospect', 'of', 'spending'): 1, ('of', 'spending', 'an'): 1, ('spending', 'an', 'evening'): 1, ('an', 'evening', 'with'): 1, ('evening', 'with', 'a'): 1, ('with', 'a', 'poor'): 1, ('a', 'poor', 'invalid'): 1, ('poor', 'invalid', 'is'): 1, ('invalid', 'is', 'not'): 1, ('is', 'not', 'too'): 1, ('not', 'too', 'terrible'): 1, ('too', 'terrible', 'i'): 1, ('terrible', 'i', 'shall'): 1, ('i', 'shall', 'be'): 1, ('shall', 'be', 'very'): 1, ('be', 'very', 'charmed'): 1, ('very', 'charmed', 'to'): 1, ('charmed', 'to', 'see'): 1, ('to', 'see', 'you'): 1, ('see', 'you', 'tonight'): 1, ('you', 'tonight', 'between'): 1, ('tonight', 'between', '7'): 1, ('between', '7', 'and'): 1, ('7', 'and', '10'): 1, ('and', '10', 'annette'): 1, ('10', 'annette', 'scherer'): 1, ('annette', 'scherer', '~'): 1, ('scherer', '~', '~'): 1, ('~', '~', 'heavens'): 1, ('~', 'heavens', '~'): 1, ('heavens', '~', '~'): 1})\n"
          ]
        }
      ],
      "source": [
        "# Test your implementation on some sentences from the corpus we downloaded above\n",
        "# and verify if it works correctly.\n",
        "text = corpus[:10]\n",
        "print(text)\n",
        "\n",
        "ngrams = generate_ngrams_sentences(text, 3)\n",
        "print(ngrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "pgDfiTQjl3GV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "c87d9814-22e0-461c-a308-9d2a337756aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "warmup-ngram results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>warmup-ngram</pre></strong> passed!</p>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "grader.check(\"warmup-ngram\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igo0_GcfRcX7",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "__Question:__ Plot a histogram of counts vs. number of unigrams with that count (you can choose a subset of the corpus, say 500 sentences). Repeat for bigrams and trigrams. They should be all placed into a single plot. _(3 points)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "id": "pccdFETSl3GV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "238bb1e6-79df-4237-cf11-2f8d5497dbda"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, axs = plt.subplots(1, 3, tight_layout=True)\n",
        "\n",
        "# Picks a subset of the corpus\n",
        "text = corpus[:500]\n",
        "\n",
        "# Unigram counts\n",
        "unigrams = Counter()\n",
        "unigrams.update(generate_ngrams_sentences(text, 1))\n",
        "unigram_counts = list(unigrams.values())\n",
        "axs[0].hist(unigram_counts, bins=range(1, max(unigram_counts) + 1), alpha=0.9, color='blue')\n",
        "axs[0].set_title('Unigram Counts')\n",
        "axs[0].set_xlabel('Count of Unigrams')\n",
        "axs[0].set_ylabel('Number of Unigrams')\n",
        "\n",
        "# Bigram counts\n",
        "bigrams = Counter()\n",
        "bigrams.update(generate_ngrams_sentences(text, 2))\n",
        "bigram_counts = list(bigrams.values())\n",
        "axs[1].hist(bigram_counts, bins=range(1, max(bigram_counts) + 1), alpha=0.9, color='green')\n",
        "axs[1].set_title('Bigram Counts')\n",
        "axs[1].set_xlabel('Count of Bigrams')\n",
        "axs[1].set_ylabel('Number of Bigrams')\n",
        "\n",
        "# Trigram counts\n",
        "trigrams = Counter()\n",
        "trigrams.update(generate_ngrams_sentences(text, 3))\n",
        "trigram_counts = list(trigrams.values())\n",
        "axs[2].hist(trigram_counts, bins=range(1, max(trigram_counts) + 1), alpha=0.9, color='red')\n",
        "axs[2].set_title('Trigram Counts')\n",
        "axs[2].set_xlabel('Count of Trigrams')\n",
        "axs[2].set_ylabel('Number of Trigrams')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "lOBzYm5Yl3GV"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "__Question:__ What observation can you make from the plots? _(2 points)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "4m3ctuMZl3GV"
      },
      "source": [
        "__Answer:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHw3RXbPl3GW"
      },
      "source": [
        "The frequency of n-grams reduces as we go from unigrams to trigrams. The distribution spreads out with many of them having low frequencies. This could mean that individual words can be found more than longer sequences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtFid2zSLIaU",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "### Implementing an n-gram language model\n",
        "\n",
        "Next, you will implement a class for an trigram (n=3) language model. This will be a barebones trigram LM, i.e., no smoothing or OOV handling is required. Complete\n",
        "the functions in the following `NgramLM` class. _(20 points)_\n",
        "\n",
        "Note that the class itself is\n",
        "for a general n-gram LM, but we will instantiate it with n=3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8sHS1fYl3GW"
      },
      "source": [
        "_Type your answer here, replacing this text._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TEDwFtlFMNhP",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class NgramLM(object):\n",
        "    \"\"\"A basic n-gram language model without any smoothing.\"\"\"\n",
        "\n",
        "    def __init__(self, n: int):\n",
        "        assert (isinstance(n, int) and n > 0)\n",
        "\n",
        "        self.n: int = n\n",
        "        self.vocab: Set[str] = set()  # A set of all words appearing in the corpus.\n",
        "        self.ngrams = Counter()  # count(ABC) - Dict[Tuple, int]\n",
        "        self.ngram_contexts = Counter()  # count(AB) - Dict[Tuple, int]\n",
        "        self.contexts = defaultdict(set)  # {AB: {C1,C2,C2}} - Dict[Tuple, Set[str]]\n",
        "\n",
        "    def generate_ngrams(self, text: List[str]) -> Counter:\n",
        "        \"\"\"Generates all n-grams (i.e. n-1 context words) for the given text.\n",
        "        In this method, we assume n is defined at the class initialization,\n",
        "        so you should use `self.n`.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        text : List[str]\n",
        "            Input text (list of strings) after tokenization.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        ngrams : Counter\n",
        "            Output n-grams dictionary as {ngram: count} (Dict[Tuple, int]),\n",
        "            where `ngram` is a n-gram tuple and `count` is an integer count.\n",
        "            e.g. ('Mary','has') and value as count of the n-gram in the text.\n",
        "        \"\"\"\n",
        "        return generate_ngrams(text, self.n)\n",
        "\n",
        "    def generate_ngrams_sentences(self, text: List[List[str]]) -> Counter:\n",
        "        \"\"\"Generates n-grams for each sentence and aggregates them.\"\"\"\n",
        "        return generate_ngrams_sentences(text, self.n)\n",
        "\n",
        "    def update(self, text: List[str]):\n",
        "        \"\"\"Updates the model n-grams based on the given text input.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        text : List[str]\n",
        "        \"\"\"\n",
        "        # TODO: Your code here\n",
        "        ngrams = self.generate_ngrams(text)\n",
        "        for ngram,count in ngrams.items():\n",
        "          self.ngrams[ngram] += count\n",
        "          context = ngram[:-1]\n",
        "          word = ngram[-1]\n",
        "          self.ngram_contexts[context] += count\n",
        "          self.contexts[context].add(word)\n",
        "          self.vocab.update(ngram)\n",
        "\n",
        "    def word_prob(self, context: Tuple[str], word: str) -> float:\n",
        "        \"\"\"Returns the probability of a word given a context. The context is a\n",
        "        string of words, with length n-1.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        context : Tuple[str]\n",
        "            A tuple of words describing the context for the next word.\n",
        "        word : str\n",
        "            The next word that the probability is computed for.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        prob : float\n",
        "            The estimated probability of the next word given the context.\n",
        "        \"\"\"\n",
        "        # TODO: Your code here\n",
        "        if context not in self.ngram_contexts or (context + (word,)) not in self.ngrams:\n",
        "              return 0.0\n",
        "        return self.ngrams[context + (word,)] / self.ngram_contexts[context]\n",
        "\n",
        "    def next_word_candidates(self, context: Tuple[str]) -> List[str]:\n",
        "        \"\"\"Generates a list of tokens based on the given context, which would be\n",
        "        later used as candidates for the next word prediction.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        context : Tuple[str]\n",
        "            A tuple of words describing the context for the next word.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        words : List[str]\n",
        "            A list of candidate tokens for the next word.\n",
        "        \"\"\"\n",
        "        if context not in self.contexts:\n",
        "              return []\n",
        "        return list(self.contexts[context])\n",
        "\n",
        "    def random_word(self, context: Tuple[str]) -> str:\n",
        "        \"\"\"Generates a random word based on the given context.\n",
        "\n",
        "        Note:\n",
        "        Please use a random function from `random` instead of `numpy`;\n",
        "        otherwise, the autograder might not be happy.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        context : Tuple[str]\n",
        "            A tuple of words describing the context for the next word.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        word : str\n",
        "            One randomly drawn word from the distribution defined given the context.\n",
        "        \"\"\"\n",
        "        assert context in self.contexts, f'Encountered unseen context={context}.'\n",
        "\n",
        "        potential_random_word = self.next_word_candidates(context)\n",
        "        occur_chance = [self.word_prob(context,i) for i in potential_random_word]\n",
        "        return random.choices(potential_random_word, weights=occur_chance)[0]\n",
        "\n",
        "    def random_text(self, length: int) -> List[str]:\n",
        "        \"\"\"Generates random text of the specified word length excluding \"~\" (BOS).\n",
        "\n",
        "        Note:\n",
        "        - The final word of the generated text *can* be \"~\" (EOS), but it is not necessary.\n",
        "        - The generation should always start with \"~\" (BOS).\n",
        "        - Only the number of starting \"~\" (BOS) is excluded from the generation, any\n",
        "        ending \"~\" (EOS) is still counted to the `length`. It means that you should\n",
        "        draw a number of `length` samples.\n",
        "\n",
        "        Note:\n",
        "        Please use a random function from `random` instead of `numpy`;\n",
        "        otherwise, the autograder might not be happy.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        length : int\n",
        "            The designated length to generate.\n",
        "\n",
        "        \"\"\"\n",
        "        if length == 0:\n",
        "          return []\n",
        "        context = ('~',) * (self.n - 1)\n",
        "        final_text = []\n",
        "        for _ in range(length):\n",
        "          next_word = self.random_word(context)\n",
        "          final_text.append(next_word)\n",
        "          context = (*context[1:], next_word)\n",
        "\n",
        "        return final_text\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "code",
        "id": "8krtKhK7XLbM",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Training block for a trigram language model\n",
        "trigramlm = NgramLM(3)\n",
        "for sentence in corpus:\n",
        "    trigramlm.update(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Cs_N0phol3GW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "9e6c6f86-f4ed-4caa-e8b1-7d5080db43bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ngramlm-impl results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>ngramlm-impl</pre></strong> passed!</p>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "grader.check(\"ngramlm-impl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6tjcHSLol3GX"
      },
      "source": [
        "__Question:__ What is the size of the training data (number of tokens)? _(1 point)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "id": "vNh0lq9Jl3GX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e3af36e-d97b-4a90-b300-dd1544a88789"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "571824"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "training_corpus_size = sum(len(tokens) for tokens in corpus)\n",
        "training_corpus_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "iTHJnKx_l3GX"
      },
      "source": [
        "__Question:__ What is the size of the vocabulary? _(1 point)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "id": "TFblKI62l3GX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab55b73-e7ec-4c71-fc4b-06c5c64aa42f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17511"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "trigramlm_vocab_size = len(trigramlm.vocab)\n",
        "trigramlm_vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "shhXhONFl3GX"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "__Question:__ What is the optimal time complexity of computing ngrams? How long does the training take? _(2 points)_\n",
        "\n",
        "*Note*: please use big-O notation to show the time complexity and explain variables involved accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6vVw8VHJl3GX"
      },
      "source": [
        "__Answer:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL12R_YBl3GX"
      },
      "source": [
        "Time Complexity depends on number of tokens t and length of the n-gram n. Total time will be (t - n + 1) to get all the n-grams as we slide over all the tokens in the dataset and portion off size n. So, the time complexity is O(t) i.e., linear time. Training will also take O(t) as updating the counts in hash map takes constant time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "id": "bgVeiqNMl3GX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f63cab-d6bc-41f8-bdff-85d7ed2099a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.5032804012298584"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# TODO: put the training time (in ms) of a trigram LM below.\n",
        "import time\n",
        "start = time.time()\n",
        "trigramlm = NgramLM(3)\n",
        "for sentence in corpus:\n",
        "    trigramlm.update(sentence)\n",
        "end = time.time()\n",
        "trigram_training_time = end - start\n",
        "trigram_training_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5RC2nZbUl3GX"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "__Question:__ How would the training time scale if you have a corpus containing 1 billion tokens? Is this training time reasonable? If not, can you think of ways to improve it? _(2 points)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlxn8YSdasgO",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "__Answer:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ3k6C5pl3GX"
      },
      "source": [
        "The training time would scale linearly as time complexity is linear in nature. 1 billion tokens should be feasible but there could be memory utilization issues due to large number of tokens. We can use parallel processing (use multiple processors) to improve the performance. We can also use sampling to reduce the number of tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxTPrtaKbzf5",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "#### Predicting/generating text using the trained LM\n",
        "\n",
        "One of the applications of an LM is to automatically predict the next word given a context (such as in Smart Keyboards), or to generate a piece of text of a given length. Use the `random_word` and `random_text` functions you implemented earlier to answer the questions below. For full credit, you need to show how you arrived at the answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgQQ-KgTeGFm",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "__Question:__ Please implement the function that computes an empirical distribution for the next word prediction conditioning on a context. Consider the context \"by her\". You can generate a random word for a large number of times, say 1000, using this context and count how many times each word are generated to calculate its empirical probability accordingly. _(3 points)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "id": "Hrr8pjJCl3GX"
      },
      "outputs": [],
      "source": [
        "def compute_empirical_distribution(model: NgramLM, context: Tuple[str], num_samples: int) -> Dict[str, float]:\n",
        "    \"\"\"Computes an empirical distribution for the next word conditioning on the given context.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : NgramLM\n",
        "        A trained Ngram Language Model.\n",
        "    context : Tuple[str]\n",
        "        The context used to predict a next word.\n",
        "    num_samples : int\n",
        "        The number of samples to be drawn to compute the empirical distribution.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    emp_distr : Dict[str, float]\n",
        "        An empirical distribution for the next word\n",
        "\n",
        "    \"\"\"\n",
        "    wfreq = defaultdict(int)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        word = model.random_word(context)\n",
        "        wfreq[word] += 1\n",
        "\n",
        "    total_words = sum(wfreq.values())\n",
        "    emp_distr = {word: count / total_words for word, count in wfreq.items()}\n",
        "\n",
        "    return emp_distr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": true,
        "tags": [],
        "id": "5tLy5kSjl3GX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff7170a-2dfe-4e2c-d0c1-be9295a1ce35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'that': 0.023,\n",
              " 'body': 0.012,\n",
              " '~': 0.082,\n",
              " 'bare': 0.023,\n",
              " 'friend': 0.019,\n",
              " 'brother': 0.023,\n",
              " 'husband': 0.089,\n",
              " 'side': 0.03,\n",
              " 'thoughts': 0.024,\n",
              " 'serious': 0.027,\n",
              " 'fullness': 0.022,\n",
              " 'breadth': 0.02,\n",
              " 'image': 0.018,\n",
              " 'sister': 0.045,\n",
              " 'father': 0.061,\n",
              " 'smiles': 0.013,\n",
              " 'mother': 0.093,\n",
              " 'garments': 0.027,\n",
              " 'and': 0.023,\n",
              " 'own': 0.023,\n",
              " 'marriage': 0.024,\n",
              " 'massive': 0.031,\n",
              " 'look': 0.025,\n",
              " 'manners': 0.023,\n",
              " 'spiritual': 0.021,\n",
              " 'face': 0.014,\n",
              " 'daughter': 0.027,\n",
              " 'attitude': 0.035,\n",
              " 'feelings': 0.023,\n",
              " 'beauty': 0.015,\n",
              " 'self': 0.022,\n",
              " 'presence': 0.027,\n",
              " 'daughters': 0.016}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "compute_empirical_distribution(trigramlm, ('by', 'her'), 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "12AAUdZpl3GX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "23d12dec-5760-4d02-89ab-89701aef9a3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ngramlm-empirical-distribution results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>ngramlm-empirical-distribution</pre></strong> passed!</p>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "grader.check(\"ngramlm-empirical-distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "9wOIHp1-l3GY"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "__Question:__ Does the empirical probability match the output of `word_prob((\"by\", \"her\"), \"husband\")`? Could you explain why it matches or not? Could you propose a way to measure how the empirical distribution differs from the theoretical distribution? _(3 points)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "gej9Q0Ldl3GY"
      },
      "source": [
        "__Answer:__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trigramlm.word_prob(('by', 'her'), 'husband'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40zdRz9ePyih",
        "outputId": "b8b96d85-529a-4a4f-9ffb-5a81aab3af52"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08888888888888889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjCgqKj4l3GY"
      },
      "source": [
        "No, it does not match. This is mainly because the model is trained on a small sample set. If the model is well-trained, then the empirical and theoritical probabilities will be same as they both utilize same data from n-grams. We can use KL divergence to measure how the distributions differ from each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy7Rtc7L6psV",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "__Question:__ Generate a random text of length 100 words. Comment on the local and global semantics of the generated text. _(2 points)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "kskAoByZl3GY"
      },
      "source": [
        "__Answer:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtyaXjtrl3GY"
      },
      "source": [
        "The local semantics are good. They make sense gramatically. The global semantics are not so good because a 3-gram lacks long term context. The sentences are gibberish and nonsensical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "id": "gcSrXyhwl3GY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ac7178-9c6c-4081-e752-cd9f2202d8dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the count s other gory leg ~ ~ and the different outlooks of these sounds ~ ~ said pierre after giving his hand ~ ~ the hounds and a passionate admiration for him to forgive himself he would go ~ ~ pierre rushed to collect my wits father said he glancing wearily round and was capable of them all and without holding on said the fever was not he ~ ~ said mademoiselle bourienne who had plainly shown before had now a rich man i must say that ~ ~ boris remembered natasha as with all your belongings to our\n"
          ]
        }
      ],
      "source": [
        "# TODO: Your code here\n",
        "generated_text=trigramlm.random_text(100)\n",
        "generated_text=' '.join(generated_text)\n",
        "print(generated_text)  # Please make sure this prints out a `str` instead of a `list`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "wjqzn5COl3GY"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "__Question:__ Now train a 4-gram LM on the same data and generate a 100-word text again. Do you observe any differences between the outputs of the two models? _(2 points)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "iepuif9Al3GY"
      },
      "source": [
        "__Answer:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs0ukwNMl3Ga"
      },
      "source": [
        "The 4-gram model produces better sounding and meaningful text locally and globally as compared to the trigram model. This is beacuse it has a larger context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": true,
        "tags": [],
        "id": "QFMvVRO4l3Ga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068480e5-91b0-4cc6-855e-1019038c9f5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.NgramLM at 0x7ce373131a60>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# You should train you 4-gram model here in the same way as training a trigram model\n",
        "# You should use the same `corpus` for training\n",
        "qgramlm = NgramLM(4)\n",
        "for sentence in corpus:\n",
        "    qgramlm.update(sentence)\n",
        "qgramlm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "id": "4EKOoAijl3Ga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52ec460-e81d-4936-a60f-0555148d71aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how can one see from there ~ ~ ~ well this is strange ~ ~ ~ let them have it ~ ~ ~ what do i care ~ ~ ~ that day he lived through many things gaining knowledge observation and experience but had he possessed all the faculties he afterwards acquired he could not did not wish or were not in vain and that prince michael zakharych was in the same place ~ ~ ~ they rode close by continuing to converse and prince andrew began to reply and to state his own plan prince dolgorukov ceased to listen\n"
          ]
        }
      ],
      "source": [
        "# TODO: Your code here\n",
        "qgram_generated_text=qgramlm.random_text(100)\n",
        "qgram_generated_text=' '.join(qgram_generated_text)\n",
        "print(qgram_generated_text)  # Please make sure this prints out a `str` instead of a `list`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxh0pOSn9N1O",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "### Evaluating the LM: Perplexity\n",
        "\n",
        "In the context of language modeling, perplexity measures how an LM predicts a sample. It is computed as the per word inverse probability of a held-out set:\n",
        "\n",
        "$$ Perplexity(W) = P(W_1 W_2 \\ldots W_N)^{-1/N} $$\n",
        "\n",
        "Complete the following function which computes the perplexity of an ngram language model given the class object and a dataset (represented as a list of strings as done earlier). _(8 points)_\n",
        "\n",
        "__Note 1:__ You may assume that the text is normalized as done before, so no text processing is required in the function.\n",
        "\n",
        "__Note 2:__ Consider performing computations in the log domain to avoid underflow errors. Recall the log equalities:\n",
        "\n",
        "$$ P = 2^{\\log_2 P} $$\n",
        "$$ \\log (a_1 a_2 \\ldots a_N)^{1/N} = \\frac{1}{N}\\left( \\log a_1 + \\log a_2 + \\ldots + \\log a_N \\right) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yg5Ezw1PK4fo",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def perplexity(model: NgramLM, data: List[List[str]]) -> float:\n",
        "    \"\"\"Function to compute perplexity of ngram LM.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : NgramLM\n",
        "        A class object denoted a trained `NgramLM`.\n",
        "    text : List[List[str]]\n",
        "        A list of sentences, where each sentence is a list of tokens.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    perp : float\n",
        "        Perplexity of the LM on given string.\n",
        "    \"\"\"\n",
        "    c_log_prob = 0.0\n",
        "    token_count = 0\n",
        "\n",
        "    for sentence in data:\n",
        "        n_gram_order = model.n - 1\n",
        "        sentence = ['~'] * n_gram_order + sentence + ['~'] * n_gram_order\n",
        "        token_count += len(sentence) - n_gram_order\n",
        "\n",
        "        for index in range(n_gram_order, len(sentence)):\n",
        "            context = tuple(sentence[index - n_gram_order:index])\n",
        "            target_word = sentence[index]\n",
        "            word_probability = model.word_prob(context, target_word)\n",
        "\n",
        "            if word_probability > 0:\n",
        "                c_log_prob += math.log2(word_probability)\n",
        "            else:\n",
        "                c_log_prob += float('-inf')\n",
        "\n",
        "    avg_log_prob = c_log_prob / token_count\n",
        "    p = 2 ** (-avg_log_prob)\n",
        "\n",
        "    return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "__lPVrGXl3Ga",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "bfa1bba6-a169-45b0-dd82-4409fdcf2062"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ngramlm-perp-impl results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>ngramlm-perp-impl</pre></strong> passed!</p>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "grader.check(\"ngramlm-perp-impl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drgo2ZhMgvTA",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "__Question:__ What is the perplexity of the model on the training corpus? _(1 point)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "eWiy10LSNhl2",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b71db5e3-cb63-455b-c2ba-60142bde457c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.118221877916317"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# TODO: Your code here\n",
        "trigram_perp_on_training = perplexity(trigramlm, corpus)\n",
        "trigram_perp_on_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Nnqd4GPDl3Ga",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "be2e97d4-354e-4377-c3ca-310a86f08663"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ngramlm-tri-perp-on-training results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>ngramlm-tri-perp-on-training</pre></strong> passed!</p>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "grader.check(\"ngramlm-tri-perp-on-training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6kIPjp58mDa",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "__Question:__ What is the perplexity of the 4-gram LM you trained earlier on the training corpus? _(1 point)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "id": "99eNyxeZl3Gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb55fca6-211f-4b97-b288-bdce47f67266"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.2828663871796584"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# TODO: Your code here\n",
        "qgram_perp_on_training = perplexity(qgramlm, corpus)\n",
        "qgram_perp_on_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "TWaHcLUil3Gb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "4742e20b-9604-4aca-fbc2-0fd3de931774"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ngramlm-quad-perp-on-training results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>ngramlm-quad-perp-on-training</pre></strong> passed!</p>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "grader.check(\"ngramlm-quad-perp-on-training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giDoTrs9ORpD",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "You will now use your above implementation to evaluate your model on a small held out development set from Leo Tolstoy's Anna Karenina. First we download and preprocess this data similar to how we did for the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "wwmOEmrt5sMW",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Process the text file to get the contents of Chapter 1\n",
        "try:\n",
        "    with open('1399-0.txt', 'r') as file:\n",
        "        dev_raw = file.read().replace('\\n', ' ')\n",
        "except FileNotFoundError:\n",
        "    with open('../../1399-0.txt', 'r') as file:\n",
        "        dev_raw = file.read().replace('\\n', ' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "zWqwXVzo6UJj",
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ff0664-34e3-44d7-eb78-b0d7bf64e30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev data has 15883 sentences\n"
          ]
        }
      ],
      "source": [
        "pattern = \"Chapter 1(.*)Chapter 2\"\n",
        "dev_ch1 = re.search(pattern, dev_raw).group(1)\n",
        "\n",
        "sentences = sent_tokenize(dev_ch1)\n",
        "\n",
        "dev_text = []\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "for sentence in sentences:\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    dev_text.append([token.lower() for token in tokens])\n",
        "\n",
        "print(\"Dev data has {} sentences\".format(len(dev_text)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi8ach2U7Tx3",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "__Question:__ Compute the perplexity of the 3-gram LM on the development set prepared above. _(1 points)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "T-qiPw6p7PcG",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12abc412-a882-45c1-f71f-8e3f4ff625ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "inf"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# TODO: Your code here\n",
        "trigram_perp_on_dev = perplexity(trigramlm, dev_text)\n",
        "trigram_perp_on_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "FeWlDzdYl3Gb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "4118914f-02d7-47cc-e35b-25f1b6b4c124"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ngramlm-tri-perp-on-dev results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>ngramlm-tri-perp-on-dev</pre></strong> passed!</p>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "grader.check(\"ngramlm-tri-perp-on-dev\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "WDho_CV2l3Gb"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "__Question:__ What is the reason for this perplexity value? _(2 points)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "M681Cczrl3Gb"
      },
      "source": [
        "__Answer:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hApl4YF1l3Gb"
      },
      "source": [
        "This is caused when the language model encounters zero probabilities or unknown tokens. We can use smoothing techniques to improve on this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJRKm-HE8B7Q",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "### Zeros and generalization\n",
        "\n",
        "From the above, you would have realized that our trigram LM in the barebones setting is probably not robust enough to be deployed in general settings, due to the data sparsity problem. This problem is dealt with by using \"smoothing\" methods for unseen n-grams and the `<UNK>` token for OOV words.\n",
        "\n",
        "In this section, you will implement Laplace (add-one) smoothing and use the `<UNK>` token for handling OOV words in the evaluation set. Complete the following class definition to achieve this. _(15 points)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "v6a4wXKvTf6E",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class NgramLMWithLaplaceSmoothing(NgramLM):\n",
        "    \"\"\"An n-gram language model with OOV handling and Laplace smoothing.\n",
        "    This class inherits all bahaviors from previous defined `NgramLM`.\n",
        "    Please be careful with the implementations here as you have to be consistent\n",
        "    with all interfaces.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n: int):\n",
        "        super(NgramLMWithLaplaceSmoothing, self).__init__(n=n)\n",
        "\n",
        "    def next_word_candidates(self, context: Tuple[str]) -> List[str]:\n",
        "        \"\"\"Generates a list of tokens based on the given context, which would be\n",
        "        later used as candidates for the next word prediction.\n",
        "\n",
        "        Note: in this overriden version, you should deal with the OOV words.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        context : Tuple[str]\n",
        "            A tuple of words describing the context for the next word.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        words : List[str]\n",
        "            A list of candidate tokens for the next word.\n",
        "        \"\"\"\n",
        "        if context not in self.contexts:\n",
        "            return ['<UNK>']\n",
        "        return list(self.contexts[context])\n",
        "\n",
        "    def word_prob(self, context: Tuple[str], word: str) -> float:\n",
        "        \"\"\"Returns the probability of a word given a context. The context is a\n",
        "        string of words, with length n-1.\n",
        "\n",
        "        Note: in this overriden version, you should deal with the OOV words.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        context : Tuple[str]\n",
        "            A tuple of words describing the context for the next word.\n",
        "        word : str\n",
        "            The next word that the probability is computed for.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        prob : float\n",
        "            The estimated probability of the next word given the context.\n",
        "        \"\"\"\n",
        "        if word not in self.vocab:\n",
        "            word = '<UNK>'\n",
        "\n",
        "        # Applying Laplace smoothing\n",
        "        context_count = self.ngram_contexts.get(context, 0)\n",
        "        ngram_count = self.ngrams.get(context + (word,), 0)\n",
        "\n",
        "        vocab_size = len(self.vocab)\n",
        "        prob = (ngram_count + 1) / (context_count + vocab_size)\n",
        "\n",
        "        return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "id": "TXX1--Dxl3Gb"
      },
      "outputs": [],
      "source": [
        "# Training block for a trigram language model with Laplace smoothing\n",
        "trigramlm_laplace = NgramLMWithLaplaceSmoothing(3)\n",
        "for sentence in corpus:\n",
        "    trigramlm_laplace.update(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE7UsXK5UL-_",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "__Question:__ Report the perplexity of the new LM on the development data. (3 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "id": "bVQdsbGRl3Gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee7b53e5-1588-4d76-bc05-0787ceabd8b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7353.30230212652"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# TODO: Your code here\n",
        "trigram_laplace_perp_on_training = perplexity(trigramlm_laplace, dev_text)\n",
        "trigram_laplace_perp_on_training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "lJd1baM1l3Gc"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "__Question:__ Can you think of a different way to solve the OOV problem? _(2 points)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "h2lLlbjDl3Gc"
      },
      "source": [
        "__Answer:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88-jmIt-l3Gc"
      },
      "source": [
        "We can use subword tokenization. Splitting of tokens will help to recognize part of a OOV word, so we need not issue a token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14Kjgo2NSc1A",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "__Question (extra credit):__ Laplace smoothing is a relatively naive smoothing method. In the lectures, you learnt about more advanced methods: Good-Turing, Backoff, Interpolation, Kneser-Ney. Implement any one of these smoothing methods (pick your favorite). Evaluate the resulting trigram LM on the development data and report the perplexity. Could you get some improvements (an improvement from the baseline would secure you to get an extra credit of 10 points)? _(10 points)_\n",
        "\n",
        "__Leaderboard:__ It would be interesting to explore different techniques or combinations of techniques to improve trigram language models. For this extra credit question, we also introduce a leaderboard for people to compete their designs of language models. To encourage participantion, the top 15% and 30% would be given another 10 points and 5 points extra credit respectively. Have fun :-)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "HapmEPF4cDUa",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class ImprovedNgramLM(NgramLM):\n",
        "    \"\"\"An improved version of n-gram language model with OOV handling.\n",
        "    This class inherits all bahaviors from previous defined `NgramLM`.\n",
        "    Please be careful with the implementations here as you have to be consistent\n",
        "    with all interfaces.\n",
        "\n",
        "    Note: you could override more methods provided by the base class, but you have\n",
        "    to maintain their ability of handling the same types of inputs and outputs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n: int):\n",
        "        super(ImprovedNgramLM, self).__init__(n=n)\n",
        "\n",
        "        # TODO: Your code here, if you would like to change the behavior of init.\n",
        "        if \"<UNK>\" not in self.vocab:\n",
        "            self.vocab.add(\"<UNK>\")\n",
        "\n",
        "    def _handle_oov(self, word: str) -> str:\n",
        "        \"\"\"Replace OOV words with <UNK>.\"\"\"\n",
        "        return word if word in self.vocab else \"<UNK>\"\n",
        "\n",
        "    def next_word_candidates(self, context: Tuple[str]) -> List[str]:\n",
        "        \"\"\"Generates a list of tokens based on the given context, which would be\n",
        "        later used as candidates for the next word prediction.\n",
        "\n",
        "        Note: in this overriden version, you should deal with the OOV words.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        context : Tuple[str]\n",
        "            A tuple of words describing the context for the next word.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        words : List[str]\n",
        "            A list of candidate tokens for the next word.\n",
        "        \"\"\"\n",
        "        # TODO: Your code here\n",
        "        clean_context = tuple(self._handle_oov(w) for w in context)\n",
        "        candidates = super().next_word_candidates(clean_context)\n",
        "\n",
        "        if \"<UNK>\" not in candidates:\n",
        "            candidates.append(\"<UNK>\")\n",
        "\n",
        "        return candidates\n",
        "\n",
        "\n",
        "    def word_prob(self, context: Tuple[str], word: str) -> float:\n",
        "        \"\"\"Returns the probability of a word given a context. The context is a\n",
        "        string of words, with length n-1.\n",
        "\n",
        "        Note: in this overriden version, you should deal with the OOV words.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        context : Tuple[str]\n",
        "            A tuple of words describing the context for the next word.\n",
        "        word : str\n",
        "            The next word that the probability is computed for.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        prob : float\n",
        "            The estimated probability of the next word given the context.\n",
        "        \"\"\"\n",
        "        # TODO: Your code here\n",
        "        clean_context = tuple(self._handle_oov(w) for w in context)\n",
        "        clean_word = self._handle_oov(word)\n",
        "\n",
        "        candidates = self.next_word_candidates(clean_context)\n",
        "\n",
        "        # Get base probs from parent LM\n",
        "        base_probs = {}\n",
        "        for w in candidates:\n",
        "            p = super().word_prob(clean_context, w)\n",
        "            base_probs[w] = max(p, 0.0)  # avoid negatives just in case\n",
        "\n",
        "        # Add-ε smoothing to ensure nonzero prob everywhere\n",
        "        eps = 1e-6\n",
        "        smoothed = {w: base_probs[w] + eps for w in candidates}\n",
        "\n",
        "        # Normalize so distribution sums to 1\n",
        "        Z = sum(smoothed.values())\n",
        "        probs = {w: smoothed[w] / Z for w in candidates}\n",
        "\n",
        "        return probs.get(clean_word, probs[\"<UNK>\"])\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "id": "neDXt1Zwl3Gc"
      },
      "outputs": [],
      "source": [
        "# Training block for a trigram language model\n",
        "improved_trigramlm = ImprovedNgramLM(3)\n",
        "for sentence in corpus:\n",
        "    improved_trigramlm.update(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "gYmH4KZ3l3Gc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fac13655-b348-42db-9752-2d2dcfbf5095"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ngramlm-improvement-impl results:\n",
              "    ngramlm-improvement-impl - 1 result:\n",
              "        Test case passed!\n",
              "\n",
              "    ngramlm-improvement-impl - 2 result:\n",
              "        Test case passed!\n",
              "\n",
              "    ngramlm-improvement-impl - 3 message: Each marginialized distribution should sum to 1 - any p > 1 would result in inf perplexity.\n",
              "\n",
              "    ngramlm-improvement-impl - 3 result:\n",
              "        Trying:\n",
              "            def pub_test_all_sum_to_1():\n",
              "                def _random_context():\n",
              "                    corpus_id = random.choices([0, 1], k=1)[0]\n",
              "                    if corpus_id == 0:  # From training\n",
              "                        sent = random.choices(corpus)[0]\n",
              "                    elif corpus_id == 1:  # From dev\n",
              "                        sent = random.choices(dev_text)[0]\n",
              "                    else: \n",
              "                        raise ValueError()\n",
              "                    if len(sent) < improved_trigramlm.n:\n",
              "                        return _random_context()\n",
              "            \n",
              "                    ctx_start = random.randint(0, len(sent) - improved_trigramlm.n)\n",
              "                    return tuple(sent[ctx_start:ctx_start + improved_trigramlm.n - 1])\n",
              "        \n",
              "                full_vocab = set(\n",
              "                    [t for s in corpus for t in s]\n",
              "                    + [t for s in dev_text for t in s]\n",
              "                    + ['feaqwfeqjio',' zji129', 'v,1..', 'feq9018']\n",
              "                    + ['~']\n",
              "                )    \n",
              "                for i in range(500):\n",
              "                    ctx = _random_context()\n",
              "                    non_unk_prob = sum([improved_trigramlm.word_prob(ctx, w) for w in full_vocab if w in improved_trigramlm.vocab])\n",
              "                    unks = [w for w in full_vocab if w not in improved_trigramlm.vocab]\n",
              "                    unk_prob = sum([improved_trigramlm.word_prob(ctx, w) for w in unks]) / len(unks)\n",
              "                    total_prob = non_unk_prob + unk_prob\n",
              "                    assert np.isclose(total_prob, 1.0, atol=5e-2) and total_prob < 1.05, f'Context={ctx}, NonUNKProb={non_unk_prob}, UNKProb={unk_prob}, Prob={total_prob}'\n",
              "            \n",
              "        Expecting nothing\n",
              "        ok\n",
              "        Trying:\n",
              "            pub_test_all_sum_to_1()\n",
              "        Expecting nothing\n",
              "        **********************************************************************\n",
              "        Line 30, in ngramlm-improvement-impl 2\n",
              "        Failed example:\n",
              "            pub_test_all_sum_to_1()\n",
              "        Exception raised:\n",
              "            Traceback (most recent call last):\n",
              "              File \"/usr/lib/python3.12/doctest.py\", line 1368, in __run\n",
              "                exec(compile(example.source, filename, \"single\",\n",
              "              File \"<doctest ngramlm-improvement-impl 2[1]>\", line 1, in <module>\n",
              "                pub_test_all_sum_to_1()\n",
              "              File \"<doctest ngramlm-improvement-impl 2[0]>\", line 28, in pub_test_all_sum_to_1\n",
              "                assert np.isclose(total_prob, 1.0, atol=5e-2) and total_prob < 1.05, f'Context={ctx}, NonUNKProb={non_unk_prob}, UNKProb={unk_prob}, Prob={total_prob}'\n",
              "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
              "            AssertionError: Context=('nurse', 'used'), NonUNKProb=17511.0, UNKProb=1.0, Prob=17512.0"
            ],
            "text/html": [
              "<p><strong style='color: red;'><pre style='display: inline;'>ngramlm-improvement-impl</pre> results:</strong></p><p><strong><pre style='display: inline;'>ngramlm-improvement-impl - 1</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>ngramlm-improvement-impl - 2</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>ngramlm-improvement-impl - 3</pre> message:</strong> Each marginialized distribution should sum to 1 - any p > 1 would result in inf perplexity.</p><p><strong><pre style='display: inline;'>ngramlm-improvement-impl - 3</pre> result:</strong></p><pre>    Trying:\n",
              "        def pub_test_all_sum_to_1():\n",
              "            def _random_context():\n",
              "                corpus_id = random.choices([0, 1], k=1)[0]\n",
              "                if corpus_id == 0:  # From training\n",
              "                    sent = random.choices(corpus)[0]\n",
              "                elif corpus_id == 1:  # From dev\n",
              "                    sent = random.choices(dev_text)[0]\n",
              "                else: \n",
              "                    raise ValueError()\n",
              "                if len(sent) < improved_trigramlm.n:\n",
              "                    return _random_context()\n",
              "            \n",
              "                ctx_start = random.randint(0, len(sent) - improved_trigramlm.n)\n",
              "                return tuple(sent[ctx_start:ctx_start + improved_trigramlm.n - 1])\n",
              "        \n",
              "            full_vocab = set(\n",
              "                [t for s in corpus for t in s]\n",
              "                + [t for s in dev_text for t in s]\n",
              "                + ['feaqwfeqjio',' zji129', 'v,1..', 'feq9018']\n",
              "                + ['~']\n",
              "            )    \n",
              "            for i in range(500):\n",
              "                ctx = _random_context()\n",
              "                non_unk_prob = sum([improved_trigramlm.word_prob(ctx, w) for w in full_vocab if w in improved_trigramlm.vocab])\n",
              "                unks = [w for w in full_vocab if w not in improved_trigramlm.vocab]\n",
              "                unk_prob = sum([improved_trigramlm.word_prob(ctx, w) for w in unks]) / len(unks)\n",
              "                total_prob = non_unk_prob + unk_prob\n",
              "                assert np.isclose(total_prob, 1.0, atol=5e-2) and total_prob < 1.05, f'Context={ctx}, NonUNKProb={non_unk_prob}, UNKProb={unk_prob}, Prob={total_prob}'\n",
              "            \n",
              "    Expecting nothing\n",
              "    ok\n",
              "    Trying:\n",
              "        pub_test_all_sum_to_1()\n",
              "    Expecting nothing\n",
              "    **********************************************************************\n",
              "    Line 30, in ngramlm-improvement-impl 2\n",
              "    Failed example:\n",
              "        pub_test_all_sum_to_1()\n",
              "    Exception raised:\n",
              "        Traceback (most recent call last):\n",
              "          File \"/usr/lib/python3.12/doctest.py\", line 1368, in __run\n",
              "            exec(compile(example.source, filename, \"single\",\n",
              "          File \"<doctest ngramlm-improvement-impl 2[1]>\", line 1, in <module>\n",
              "            pub_test_all_sum_to_1()\n",
              "          File \"<doctest ngramlm-improvement-impl 2[0]>\", line 28, in pub_test_all_sum_to_1\n",
              "            assert np.isclose(total_prob, 1.0, atol=5e-2) and total_prob < 1.05, f'Context={ctx}, NonUNKProb={non_unk_prob}, UNKProb={unk_prob}, Prob={total_prob}'\n",
              "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
              "        AssertionError: Context=('nurse', 'used'), NonUNKProb=17511.0, UNKProb=1.0, Prob=17512.0\n",
              "</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "grader.check(\"ngramlm-improvement-impl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwOF-lAWVE94",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Part 2: Parsing and the CYK algorithm\n",
        "\n",
        "In the lecture on Syntax, you learnt about parsing algorithms, including the bottom-up CYK algorithm. In this section, you will implement the CYK algorithm for computing the parse tree of a sentence given a grammar.\n",
        "\n",
        "You may look at the pseudocode on [Wikipedia](https://en.wikipedia.org/wiki/CYK_algorithm#As_pseudocode) or refer to descriptions of the CYK algorithm online (such as [this](https://courses.engr.illinois.edu/cs373/sp2009/lectures/lect_15.pdf)), but you may not copy code directly from another source. The objective of this exercise is to familiarize yourself with parsing.\n",
        "\n",
        "First, we will provide some starter code to load a simple grammar which can be used to test your implementation. The CYK algorithm only works with context-free grammars (CFGs) in the [Chomsky Normal Form (CNF)](https://en.wikipedia.org/wiki/Chomsky_normal_form), but any CFG can be represented as an equivalent CNF. You can use NLTK to check if the grammar is in CNF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44xCk4nMYVWL",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# grammar rules\n",
        "\n",
        "cfg_rules = \"\"\"\n",
        "S -> NP VP\n",
        "PP -> P NP\n",
        "NP -> Det N\n",
        "NP -> Det N PP\n",
        "NP -> 'I'\n",
        "VP -> V NP\n",
        "VP -> VP PP\n",
        "Det -> 'an'\n",
        "Det -> 'my'\n",
        "N -> 'elephant'\n",
        "N -> 'pajamas'\n",
        "V -> 'shot'\n",
        "P -> 'in'\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npLfx9CveUeI",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "__Question:__ Use NLTK to check if the grammar `cfg` is in the Chomsky Normal Form. _(1 point)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "SVY6CyYhc1zn",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c858bb33-3397-460d-85bf-f387e1ee3104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import CFG\n",
        "cfg_rules = \"\"\"\n",
        "S -> NP VP\n",
        "PP -> P NP\n",
        "NP -> Det N\n",
        "NP -> Det N PP\n",
        "NP -> 'I'\n",
        "VP -> V NP\n",
        "VP -> VP PP\n",
        "Det -> 'an'\n",
        "Det -> 'my'\n",
        "N -> 'elephant'\n",
        "N -> 'pajamas'\n",
        "V -> 'shot'\n",
        "P -> 'in'\n",
        "\"\"\"\n",
        "\n",
        "# Note:\n",
        "# `is_cfg_cnf` should be the function name without executing it (by removing `()`).\n",
        "# Executing this cell should give you a boolean result indicating whether the given CFG\n",
        "# is in the Chomsky Normal Form.\n",
        "grammar = CFG.fromstring(cfg_rules)\n",
        "is_cfg_cnf =  grammar.is_chomsky_normal_form()\n",
        "print(is_cfg_cnf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uatLXceVepso",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "__Question:__ Convert the above CFG into CNF (use pen and paper) and create a new grammar using it. Use NLTK to verify if it is in CNF. _(4 points)_\n",
        "\n",
        "Here are the steps to convert any CFG into a CNF:\n",
        "\n",
        "1. Eliminate start symbol from the RHS. If the start symbol S is at the right-hand side of any production, create a new production as: S1 -> S\n",
        "2. If CFG contains null, unit or useless production rules, eliminate them.\n",
        "3. Eliminate terminals from RHS if they exist with other terminals or non-terminals.\n",
        "4. Eliminate RHS with more than two non-terminals.\n",
        "\n",
        "(Hint: There is only one offending rule in the above grammar.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "qgnhok80g5io",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa9bf6fa-e73f-4ada-98c3-d6cc5ac041db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# Write the CNF grammar here as a string\n",
        "\n",
        "cnf_cfg_rules = \"\"\"\n",
        "S -> NP VP\n",
        "PP -> P NP\n",
        "NP -> Det N\n",
        "N1 -> N PP\n",
        "NP -> 'I'\n",
        "VP -> V NP\n",
        "VP -> VP PP\n",
        "Det -> 'an'\n",
        "Det -> 'my'\n",
        "N -> 'elephant'\n",
        "N -> 'pajamas'\n",
        "V -> 'shot'\n",
        "P -> 'in'\n",
        "\"\"\"\n",
        "\n",
        "# TODO: Your code here\n",
        "cnf_grammar = CFG.fromstring(cnf_cfg_rules)\n",
        "\n",
        "is_cnf = cnf_grammar.is_chomsky_normal_form()\n",
        "\n",
        "print(is_cnf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkL26o73dKJq",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "You can now use the above grammar and the sentence: _\"I shot an elephant in my pajamas\"_ to demonstrate your implementation of the CYK parser.\n",
        "\n",
        "Complete the following code block to implement the parser. We have provided the definition of the Node class which stores a non-terminal, and some boilerplate code to ease you into the implementation. Your main task is to implement the `parse()` function, which generates the parse table in a bottom-up manner. The `parse_table` in the `CYKParser` class below can be thought of as a table which contains number of rows equal to the number of words in the sentence. _(25 points)_\n",
        "\n",
        "_Note_:\n",
        "\n",
        "We recommend reading the usage of [NLTK grammar object](https://www.nltk.org/howto/grammar.html) as we would parse the grammar to this object. It allows us to easily play with different grammar production rules. Sample usages (`grammar` is a `nltk.grammar.CFG` object instantiated from a given grammar):\n",
        "  - `grammar.productions()`: list all production rules defined in the grammar.\n",
        "  - `rule_i = grammar.productions()[i]`: get the ith rule from the grammar.\n",
        "  - `rule_i.lhs()`: get the LHS for the given rule.\n",
        "  - `rule_i.rhs()`: get the RHS for the given rule.\n",
        "  - `rule_i.is_lexical()`: determine whether it is a terminal rule.\n",
        "  - `rule_i.is_nonlexical()`: determine whether it is a non-terminal rule.\n",
        "  - `rhs_0 = rule_i.rhs()[0]`: get the first element on the RHS for the given rule.\n",
        "  - `rhs_0.symbol()`: get the `str` symbol of the RHS element (this also applies to the LHS element).\n",
        "  \n",
        "_Hint: It may be beneficial to first run through the algorithm for the given grammar and the sentence on pen and paper._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "sk2mYJWnhomu",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "    \"\"\" Equivalent to a non-terminal. Since our grammar is CNF, a node can have at\n",
        "    most 2 children. Following 2 cases are possible:\n",
        "\n",
        "    Case 1 -> child1 is a terminal symbol\n",
        "    Case 2 -> both child1 and child2 are Nodes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, symbol, child1, child2=None):\n",
        "        self.symbol = symbol\n",
        "        self.child1 = child1\n",
        "        self.child2 = child2\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"Returns the string representation of a Node object.\"\"\"\n",
        "        return self.symbol\n",
        "\n",
        "    def generate_tree(self) -> str:\n",
        "        \"\"\"Generates the string representation of the tree rooted at the current node.\n",
        "        It is done via pre-order tree traversal.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        str_tree : str\n",
        "            The tree in its string form.\n",
        "        \"\"\"\n",
        "        if self.child2 is None:\n",
        "            return f\"[{self.symbol} '{self.child1}']\"\n",
        "        return f\"[{self.symbol} {self.child1.generate_tree()} {self.child2.generate_tree()}]\"\n",
        "\n",
        "\n",
        "class CYKParser(object):\n",
        "    \"\"\"A CYK parser which is able to parse any grammar in CNF. The parser object\n",
        "    is created from a CNF grammar and can be used to parse any sentence.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, grammar: str):\n",
        "        \"\"\"Creates a new parser object.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        grammar : str\n",
        "            Input grammar as a string of rules.\n",
        "        \"\"\"\n",
        "        self.grammar: nltk.grammar.CFG = nltk.grammar.CFG.fromstring(grammar)\n",
        "\n",
        "    def print_tree(self, parse_table: List[List[List[Node]]]):\n",
        "        \"\"\"Prints the parse tree starting with the start symbol.\n",
        "        \"\"\"\n",
        "        start_symbol = self.grammar.start().symbol()\n",
        "        final_nodes = [n for n in parse_table[-1][0] if n.symbol == start_symbol]\n",
        "        if final_nodes:\n",
        "            print(\"\\nPossible parse(s):\")\n",
        "            trees = [node.generate_tree() for node in final_nodes]\n",
        "            for tree in trees:\n",
        "                print(tree)\n",
        "        else:\n",
        "            print(\"The given sentence is not contained in the language produced by the given grammar!\")\n",
        "\n",
        "    def parse(self, sentence: List[str]) -> List[List[List[Node]]]:\n",
        "        \"\"\"Does the actual parsing according to the CYK algorithm.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        sentence : List[str]\n",
        "            An input sentence in the form of list of tokens.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        parse_table : List[List[List[Node]]]\n",
        "            The resulting parse table for the sentence under the grammar.\n",
        "        \"\"\"\n",
        "        num_tokens = len(sentence)\n",
        "        # parse_table[y][x] is the list of nodes in the x+1 cell\n",
        "        # of y+1 row in the table. That cell covers the word below it\n",
        "        # and y more words after.\n",
        "        parse_table: List[List[List[Node]]] = [[[] for x in range(num_tokens - y)] for y in range(num_tokens)]\n",
        "\n",
        "        for i, word in enumerate(sentence):\n",
        "            for rule in self.grammar.productions():\n",
        "                if rule.is_lexical() and rule.rhs()[0] == word:\n",
        "                    parse_table[0][i].append(Node(rule.lhs().symbol(), word))\n",
        "        for length in range(2, num_tokens + 1):\n",
        "            for start in range(num_tokens - length + 1):\n",
        "                for split in range(1, length):\n",
        "                    left_cell = parse_table[split - 1][start]\n",
        "                    right_cell = parse_table[length - split - 1][start + split]\n",
        "\n",
        "                    for rule in self.grammar.productions():\n",
        "                        if rule.is_nonlexical() and len(rule.rhs()) == 2:\n",
        "                            left_symbol = rule.rhs()[0].symbol()\n",
        "                            right_symbol = rule.rhs()[1].symbol()\n",
        "                            for left_node in left_cell:\n",
        "                                for right_node in right_cell:\n",
        "                                    if left_node.symbol == left_symbol and right_node.symbol == right_symbol:\n",
        "                                        parse_table[length - 1][start].append(Node(rule.lhs().symbol(), left_node, right_node))\n",
        "        return parse_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "cbDKhmkgCGmu",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "parser = CYKParser(cnf_cfg_rules)\n",
        "parse_table = parser.parse(\"I shot an elephant in my pajamas\".split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "id": "6uk7V8K9l3Gd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef87ef9-537e-4574-f5ed-e1c835381eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Possible parse(s):\n",
            "[S [NP 'I'] [VP [VP [V 'shot'] [NP [Det 'an'] [N 'elephant']]] [PP [P 'in'] [NP [Det 'my'] [N 'pajamas']]]]]\n"
          ]
        }
      ],
      "source": [
        "parser.print_tree(parse_table)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grader.check('cyk-impl')"
      ],
      "metadata": {
        "id": "Lw206TRr1PfT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "af39ba6d-df07-4ecb-ee05-38dc196c2c17"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cyk-impl results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>cyk-impl</pre></strong> passed!</p>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}